{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid purple; padding: 10px; margin: 5px\">\n",
    "<b>   Svetlana's comment  </b>\n",
    "      \n",
    "Hi Taylor, my name is Svetlana (my handle on Discord is `svetatripleten`). Congratulations on submitting another project! üéâ I will be using the standard the color marking:\n",
    "    \n",
    "\n",
    "   \n",
    "    \n",
    "<div style=\"border: 5px solid green; padding: 10px; margin: 5px\">\n",
    "\n",
    "Great solutions and ideas that can and should be used in the future are in green comments. Some of them are: \n",
    "    \n",
    "    \n",
    "- You have successfully prepared the subsets. It is important to split the data correctly in order to ensure there's no intersection;    \n",
    "    \n",
    "\n",
    "- Handled outliers; \n",
    "    \n",
    "\n",
    "- Excluded irrelevant columns to reduce computational cost;\n",
    "    \n",
    "    \n",
    "- Encoded cetegorical columns;    \n",
    "\n",
    "    \n",
    " \n",
    "- Trained and compared several models, great!\n",
    "\n",
    "    \n",
    "- Measured their training and prediction speed.\n",
    "   \n",
    "\n",
    "- Analyzed metrics. It is not enough to just fit the model and print the result. Instead, we have to analyze the results as it helps us identify what can be improved;\n",
    "  \n",
    "    \n",
    "- Wrote an excellent conclusion! A well-written conclusion shows how the project met its objectives and provides a concise and understandable summary for those who may not have been involved in the details of the project. Good job! \n",
    "\n",
    "</div>\n",
    "    \n",
    "<div style=\"border: 5px solid gold; padding: 10px; margin: 5px\">\n",
    "<b> Reviewer's comment </b>\n",
    "\n",
    "Yellow color indicates what should be optimized. This is not necessary, but it will be great if you make changes to this project. I've left several recommendations throughout the project. Please take a look.\n",
    " \n",
    "</div>\n",
    "<div style=\"border: 5px solid red; padding: 10px; margin: 5px\">\n",
    "<b> Reviewer's comment </b>\n",
    "\n",
    "Issues that must be corrected to achieve accurate results are indicated in red comments. Please note that the project cannot be accepted until these issues are resolved. For instance,\n",
    "\n",
    "\n",
    "\n",
    "- Check the data for the duplicates after you drop columns. If a dropped column contained unique values (ID or timestamp), removing it may make multiple rows appear the same;\n",
    "\n",
    "\n",
    "- We have too many gaps to drop them. Instead, consider replacing them with some unique value, such as \"Unknown\". It is normal that sometimes sellers do not specify some information. The model should \"know\" about such cases. \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "- According to the task, we need to train LGBM as well;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "There may be other issues that need your attention. I described everything in my comments.  \n",
    "</div>        \n",
    "<hr>\n",
    "    \n",
    "<font color='dodgerblue'>**To sum up:**</font> great job here! You demonstrated strong analytical and modeling skills by preparing the data, experimenting with multiple advanced models, and evaluating them with appropriate metrics. The conclusion clearly communicates which model offers the best trade-off between speed and RMSE. There are several issues that need your attention. Please take a look at my comments and do not hesitate to ask questions if some of them seem unclear. I will wait the project for the second review üòä \n",
    "    \n",
    "\n",
    "<hr>\n",
    "    \n",
    "Please use some color other than those listed to highlight answers to my comments.\n",
    "I would also ask you **not to change, move or delete my comments** to make it easier for me to navigate during the next review.\n",
    "    \n",
    "<hr> \n",
    "    \n",
    "‚úçÔ∏è Some notes:\n",
    "\n",
    "\n",
    "- Here's a link to [Supervised Learning documenation sections](https://scikit-learn.org/stable/supervised_learning.html) that you may find useful.\n",
    "\n",
    "\n",
    "\n",
    "- There are advanced tools such as [ColumnTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html) and [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html). `ColumnTransformer` and `Pipeline` are essential tools that help us create robust, maintainable, and efficient machine learning workflows. They work with data much more effectively. You can handle different data types and it is much easier to avoid data leakage. The code organization is very clean, but it may seem a bit difficult at the beginning. Take a look at this page to learn how to [organize a pipeline with ColumnTransformer](https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html).  \n",
    "<hr>\n",
    "    \n",
    "    \n",
    "üìå Please feel free to schedule a 1:1 sessions with our tutors or TAs Feel free to book 1-1 session [here](https://calendly.com/tripleten-ds-experts-team), join daily coworking sessions, or ask questions in the sprint channels on Discord if you need assistance üòâ \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid purple; padding: 10px; margin: 5px\">\n",
    "<b>   Matias's comment  </b>\n",
    "      \n",
    "Thanks for following Svetlana's red comments and congrats on your approval, Taylor!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rusty Bargain used car sales service is developing an app to attract new customers. In that app, you can quickly find out the market value of your car. You have access to historical data: technical specifications, trim versions, and prices. You need to build the model to determine the value. \n",
    "\n",
    "Rusty Bargain is interested in:\n",
    "\n",
    "- the quality of the prediction;\n",
    "- the speed of the prediction;\n",
    "- the time required for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Timing utility\n",
    "import time\n",
    "\n",
    "# To ignore warnings during model training\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('/datasets/car_data.csv')\n",
    "\n",
    "# Basic cleanup (adjust depending on your previous preprocessing steps)\n",
    "data = data.drop(['DateCrawled', 'DateCreated', 'LastSeen', 'NumberOfPictures', 'PostalCode'], axis=1)\n",
    "\n",
    "# Fill missing categorical values\n",
    "for col in ['VehicleType', 'Gearbox', 'Model', 'FuelType', 'NotRepaired']:\n",
    "    data[col] = data[col].fillna('Unknown')\n",
    "\n",
    "# Merge similar values\n",
    "data['FuelType'] = data['FuelType'].replace({'gasoline': 'petrol'})\n",
    "\n",
    "# Fill missing prices with grouped median\n",
    "data['Price'] = data.groupby(['Model', 'RegistrationYear'])['Price'].transform(\n",
    "    lambda x: x.fillna(x.median())\n",
    ")\n",
    "\n",
    "# Filter outliers\n",
    "data = data[\n",
    "    (data['Price'] >= 100) & (data['Price'] <= 100000) &\n",
    "    (data['RegistrationYear'] >= 1980) & (data['RegistrationYear'] <= 2022) &\n",
    "    (data['Power'] >= 10) & (data['Power'] <= 500)\n",
    "]\n",
    "\n",
    "# Drop columns that aren't needed\n",
    "data = data.drop(['RegistrationMonth'], axis=1)\n",
    "\n",
    "# Drop duplicates\n",
    "data = data.drop_duplicates().reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation (Revised Based on Reviewer Feedback)\n",
    "\n",
    "In this step, we performed improved data cleaning and preparation to make the dataset suitable for machine learning, while minimizing data loss and enhancing model robustness:\n",
    "\n",
    "1. **Loaded the dataset** from `/datasets/car_data.csv`.\n",
    "\n",
    "2. **Dropped irrelevant columns**:\n",
    "   - Removed columns like `DateCrawled`, `DateCreated`, `LastSeen`, `NumberOfPictures`, and `PostalCode`, which don't contribute to predicting price and can introduce noise.\n",
    "\n",
    "3. **Handled missing values**:\n",
    "   - For categorical columns (`VehicleType`, `Gearbox`, `Model`, `FuelType`, `NotRepaired`), missing values were replaced with `\"Unknown\"` instead of being dropped.\n",
    "   - This ensures that potentially useful data isn't discarded due to incomplete entries.\n",
    "\n",
    "4. **Unified inconsistent categories**:\n",
    "   - Merged similar fuel types (e.g., `\"gasoline\"` replaced with `\"petrol\"`) to reduce redundancy in encoding.\n",
    "\n",
    "5. **Filled in missing price values**:\n",
    "   - Where `Price` was missing, it was imputed using the **median price** grouped by `Model` and `RegistrationYear`, helping to retain valuable but incomplete rows.\n",
    "\n",
    "6. **Removed outliers and unrealistic values**:\n",
    "   - Kept only cars priced between **‚Ç¨100 and ‚Ç¨100,000**.\n",
    "   - Kept only cars registered between **1980 and 2022**.\n",
    "   - Filtered horsepower values to between **10 hp and 500 hp**.\n",
    "\n",
    "7. **Dropped RegistrationMonth**:\n",
    "   - Removed this column to simplify the model and avoid overfitting on a variable with weak signal strength.\n",
    "\n",
    "8. **Removed duplicates**:\n",
    "   - After column cleanup, duplicates were checked and removed to prevent data leakage or training bias.\n",
    "\n",
    "9. **Reset the index** to ensure a clean DataFrame structure.\n",
    "\n",
    "This cleaning process prepares a realistic and practical dataset, preserving useful patterns without introducing model bias through over-filtering.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid green; padding: 10px; margin: 5px\">\n",
    "<b>   Reviewer's comment </b>\n",
    "    \n",
    "Agreed! We don't need some of the columns. \n",
    "    \n",
    "</div>\n",
    "<div style=\"border: 5px solid gold; padding: 10px; margin: 5px\">\n",
    "<b>   Reviewer's comment </b>\n",
    "\n",
    "- You can save some gaps and replace them with median price in groupping by model and registration year. Yes, registration year does not define the vehicle's age, but still. \n",
    "\n",
    "    \n",
    "- You can then drop `RegistrationMonth`. It will significantly simplify the training process. \n",
    "\n",
    "\n",
    "- Another option is to drop `VehicleType` and `Brand`, since we have `Model` that should reflect both. \n",
    "\n",
    "\n",
    "- It will be perfect if you analyze the distributions and display the charts, thus showing a reader why you decided to delete specific rows. Why is this important? In real-world problems, the data is rarely clean. Displaying distributions help us evaluate the data, find outliers, identify the required preprocessing steps and understand feature relationships, which informs feature engineering. Feature engineering in some cases is a clue.\n",
    "\n",
    "\n",
    "\n",
    "- Consider analyzing categories as well. Petrol and gasoline refer to the same fuel, so we can use one of these categories. There are also some rare model categories that can be dropped. If a category appears only in the training or validation subset, for instance, and we use `handle_unknown='ignore'`, the linear model might miss important signals in validation or make predictions with incomplete features thus breaking the assumptions of linearity. It may be helpful to make sure that training and validation subsets use the same feature columns after encoding. \n",
    "</div>\n",
    "<div style=\"border: 5px solid red; padding: 15px; margin: 5px\">\n",
    "<b> Reviewer's comment</b>\n",
    "    \n",
    "- Let's not drop so many rows :) Instead, replace missing values with some unique row, such as \"Unknown\". Moreover, it is normal that sometimes sellers do not specify some information. The model should \"know\" about such cases.\n",
    "\n",
    "\n",
    "- After removing unnecessary columns, it makes sense to check the data for duplicates again, as the dataset will later be splitted into training and test sets. Removing specific columns can cause previously distinct rows to become identical. If a dropped column contained unique values (ID or timestamp), removing it may make multiple rows appear the same.   \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid green; padding: 10px; margin: 5px\">\n",
    "<b>   Reviewer's comment Iter 2</b>\n",
    "    \n",
    "Great job ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM is installed and ready to use.\n"
     ]
    }
   ],
   "source": [
    "import lightgbm\n",
    "print(\"LightGBM is installed and ready to use.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Model  Train Time (s)  Predict Time (s)  Validation RMSE\n",
      "0  Linear Regression        6.252804          0.249876      2475.580187\n",
      "1      Decision Tree        0.514149          0.055528      1976.326538\n",
      "2      Random Forest       21.837047          0.788469      1661.316088\n",
      "3           LightGBM        1.942370          0.212684      1612.084454\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Split features and target\n",
    "X = data.drop('Price', axis=1)\n",
    "y = data['Price']\n",
    "\n",
    "# Identify categorical and numerical features\n",
    "cat_features = X.select_dtypes(include='object').columns.tolist()\n",
    "num_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Step 1: Split into Train+Validation and Test sets\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Step 2: Split Train+Validation into Train and Validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)\n",
    "# Now: 60% train, 20% validation, 20% test\n",
    "\n",
    "# ---------- Pipelines ---------- #\n",
    "\n",
    "# Linear Regression with OneHotEncoder\n",
    "ohe = ColumnTransformer(\n",
    "    transformers=[('cat', OneHotEncoder(handle_unknown='ignore', sparse=False), cat_features)],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "lr_model = Pipeline([\n",
    "    ('encoder', ohe),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "start = time.time()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_train_time = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "lr_preds = lr_model.predict(X_valid)\n",
    "lr_predict_time = time.time() - start\n",
    "lr_rmse = mean_squared_error(y_valid, lr_preds, squared=False)\n",
    "\n",
    "# Decision Tree and Random Forest with OrdinalEncoder\n",
    "oe = ColumnTransformer(\n",
    "    transformers=[('cat', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), cat_features)],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = Pipeline([\n",
    "    ('encoder', oe),\n",
    "    ('model', DecisionTreeRegressor(max_depth=10, random_state=42))\n",
    "])\n",
    "\n",
    "start = time.time()\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_train_time = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "dt_preds = dt_model.predict(X_valid)\n",
    "dt_predict_time = time.time() - start\n",
    "dt_rmse = mean_squared_error(y_valid, dt_preds, squared=False)\n",
    "\n",
    "# Random Forest\n",
    "rf_model = Pipeline([\n",
    "    ('encoder', oe),\n",
    "    ('model', RandomForestRegressor(n_estimators=100, max_depth=15, random_state=42))\n",
    "])\n",
    "\n",
    "start = time.time()\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_train_time = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "rf_preds = rf_model.predict(X_valid)\n",
    "rf_predict_time = time.time() - start\n",
    "rf_rmse = mean_squared_error(y_valid, rf_preds, squared=False)\n",
    "\n",
    "# LightGBM - no encoder needed if cat features are categorical dtype\n",
    "X_train_lgbm = X_train.copy()\n",
    "X_valid_lgbm = X_valid.copy()\n",
    "for col in cat_features:\n",
    "    X_train_lgbm[col] = X_train_lgbm[col].astype('category')\n",
    "    X_valid_lgbm[col] = X_valid_lgbm[col].astype('category')\n",
    "\n",
    "lgbm_model = LGBMRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "\n",
    "start = time.time()\n",
    "lgbm_model.fit(X_train_lgbm, y_train)\n",
    "lgbm_train_time = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "lgbm_preds = lgbm_model.predict(X_valid_lgbm)\n",
    "lgbm_predict_time = time.time() - start\n",
    "lgbm_rmse = mean_squared_error(y_valid, lgbm_preds, squared=False)\n",
    "\n",
    "# ---------- Results Table ---------- #\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Linear Regression', 'Decision Tree', 'Random Forest', 'LightGBM'],\n",
    "    'Train Time (s)': [lr_train_time, dt_train_time, rf_train_time, lgbm_train_time],\n",
    "    'Predict Time (s)': [lr_predict_time, dt_predict_time, rf_predict_time, lgbm_predict_time],\n",
    "    'Validation RMSE': [lr_rmse, dt_rmse, rf_rmse, lgbm_rmse]\n",
    "})\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 20, 'n_estimators': 300, 'num_leaves': 50}\n",
      "Validation RMSE (tuned LGBM): 1553.90\n",
      "Prediction Time (s): 0.5935\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Convert categorical columns to 'category' dtype for LightGBM\n",
    "X_train_lgbm = X_train.copy()\n",
    "X_valid_lgbm = X_valid.copy()\n",
    "for col in cat_features:\n",
    "    X_train_lgbm[col] = X_train_lgbm[col].astype('category')\n",
    "    X_valid_lgbm[col] = X_valid_lgbm[col].astype('category')\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 300],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'num_leaves': [31, 50],\n",
    "}\n",
    "\n",
    "# Create the model\n",
    "lgbm = LGBMRegressor(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=lgbm,\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train_lgbm, y_train)\n",
    "\n",
    "# Best model\n",
    "best_lgbm = grid_search.best_estimator_\n",
    "\n",
    "# Predict and evaluate on validation set\n",
    "start = time.time()\n",
    "lgbm_preds = best_lgbm.predict(X_valid_lgbm)\n",
    "lgbm_predict_time = time.time() - start\n",
    "lgbm_rmse = mean_squared_error(y_valid, lgbm_preds, squared=False)\n",
    "\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Validation RMSE (tuned LGBM): {lgbm_rmse:.2f}\")\n",
    "print(f\"Prediction Time (s): {lgbm_predict_time:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Model        Train Time (s)  Predict Time (s)  Validation RMSE\n",
      "0  Linear Regression              6.252804          0.249876      2475.580187\n",
      "1      Decision Tree              0.514149          0.055528      1976.326538\n",
      "2      Random Forest             21.837047          0.788469      1661.316088\n",
      "3           LightGBM               1.94237          0.212684      1612.084454\n",
      "4   LightGBM (Tuned)  (see GridSearch log)          0.593513      1553.900028\n"
     ]
    }
   ],
   "source": [
    "# Append tuned LightGBM results to the table\n",
    "tuned_results = pd.DataFrame({\n",
    "    'Model': ['LightGBM (Tuned)'],\n",
    "    'Train Time (s)': ['(see GridSearch log)'],  # You can time it manually if needed\n",
    "    'Predict Time (s)': [lgbm_predict_time],\n",
    "    'Validation RMSE': [lgbm_rmse]\n",
    "})\n",
    "\n",
    "results = pd.concat([results, tuned_results], ignore_index=True)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid green; padding: 15px; margin: 5px\">\n",
    "<b>   Reviewer's comment </b>\n",
    "    \n",
    "Yes, we need to encode data here, well done! It is acceptable to use `get_dummies` in this project, and we have to use it before we split the data because if we use it after we divide the data, we may face the situation where subsest have different number of categories.\n",
    "    \n",
    "</div>\n",
    "<div style=\"border: 5px solid gold; padding: 15px; margin: 5px\">\n",
    "<b>   Reviewer's comment </b>\n",
    "\n",
    "\n",
    "- Consider saving at least one subset for the final testing. The best way to evaluate the model is to train it on the training data, calculate its metric on validation data, and, in the very end of the project, train the best model (it's usually one model) on the hold-out subset, the test subset. In this case, we need 3 subsets. However, if you use GridSearch, it is enough to have two subset, since GridSearch implements cross-validation.\n",
    "\n",
    "\n",
    "- If the columns we want to convert are not explicitly specified, `get_dummies` will convert all columns with categorical strings, which may lead to unexpected results if some numeric columns also contain categorical data represented in numerical form (if there's a numerical category displayed as [1, 2, 3, 2, ... ]).\n",
    "\n",
    "\n",
    "    \n",
    "- Please note that `OneHotEncoder(handle_unknown='ignore')` or `OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)` are generally more robust than `get_dummies` because they can handle situations where test subset has features that were not available during training. [Difference between OneHotEncoder and get_dummies](https://pythonsimplified.com/difference-between-onehotencoder-and-get_dummies/). \n",
    "    \n",
    "    \n",
    "    \n",
    "For tree-based models, `OrdinalEncoder` is a better choice because of computational cost. For boosting algorithms, we can rely on internal encoders that usually perform even better than external ones. For `CatBoost`, this is controlled by the `cat_features` parameter. For `LightGBM`, you can convert categorical features to the category type, allowing the model to handle them automatically.\n",
    "    \n",
    "   \n",
    "\n",
    "    \n",
    "`OrdinalEncoder()` or `LabelEncoder()` should not be used with linear models if there's no ordinal relationship. [How and When to Use Ordinal Encoder](https://leochoi146.medium.com/how-and-when-to-use-ordinal-encoder-d8b0ef90c28c). For linear regresison, I recommend using `OneHotEncoder(handle_unknown='ignore')`. \n",
    "\n",
    "\n",
    "If you decide to use any of these methods, please encode data **after** you split it. \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "For instance, you can use `Ordinal` for Forest and Tree, `OneHotEncoder` for Lin. Regression and categorical data types for boosting models.\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Model Training (Updated)\n",
    "\n",
    "In this section, we trained and compared **five machine learning models** to predict the market value of used cars.\n",
    "\n",
    "###  Models Trained:\n",
    "1. **Linear Regression** ‚Äì A fast and simple model that assumes linear relationships. Great for baseline performance.\n",
    "2. **Decision Tree Regressor** ‚Äì Learns rules from the data and splits into decision paths. Good for handling non-linear data.\n",
    "3. **Random Forest Regressor** ‚Äì An ensemble of many decision trees. More accurate but slower to train.\n",
    "4. **LightGBM Regressor** ‚Äì A fast and efficient gradient boosting framework that handles categorical features natively.\n",
    "5. **LightGBM (Tuned)** ‚Äì The LightGBM model optimized using **GridSearchCV** to improve accuracy by tuning its hyperparameters.\n",
    "\n",
    "###  Data Preparation:\n",
    "- We split the dataset into:\n",
    "  - **60% Training**\n",
    "  - **20% Validation**\n",
    "  - **20% Test (hold-out for final evaluation)**\n",
    "- For **Linear Regression**, we used `OneHotEncoder` to convert categorical features.\n",
    "- For **tree-based models**, we used `OrdinalEncoder`, which is faster and sufficient for decision-based algorithms.\n",
    "- For **LightGBM**, we converted categorical columns to `category` dtype to use LightGBM's internal encoding.\n",
    "\n",
    "###  Evaluation Metric:\n",
    "We used **RMSE (Root Mean Squared Error)** to measure prediction accuracy.  \n",
    " **Lower RMSE means better predictions**.\n",
    "\n",
    "---\n",
    "\n",
    "###  Results (on Validation Set):\n",
    "\n",
    "| Model              | Train Time (s) | Predict Time (s) | Validation RMSE |\n",
    "|--------------------|----------------|------------------|------------------|\n",
    "| Linear Regression  | 5.90 s         | 0.16 s           | 2475.58          |\n",
    "| Decision Tree      | 0.48 s         | 0.05 s           | 1976.33          |\n",
    "| Random Forest      | 20.38 s        | 0.75 s           | 1661.32          |\n",
    "| LightGBM           | 1.41 s         | 0.30 s           | 1612.08          |\n",
    "| **LightGBM (Tuned)** | _(GridSearch)_ | 0.53 s           | **1553.90**     |\n",
    "\n",
    "---\n",
    "\n",
    "### Summary:\n",
    "- **Tuned LightGBM** gave the best performance with the **lowest RMSE**.\n",
    "- **Random Forest** also performed well, though slower to train and predict.\n",
    "- **Decision Tree** was fast and decently accurate.\n",
    "- **Linear Regression** was the fastest but least accurate, useful as a simple baseline.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Model        Train Time (s)  Predict Time (s)  Validation RMSE\n",
      "0  Linear Regression              6.252804          0.249876      2475.580187\n",
      "1      Decision Tree              0.514149          0.055528      1976.326538\n",
      "2      Random Forest             21.837047          0.788469      1661.316088\n",
      "3           LightGBM               1.94237          0.212684      1612.084454\n",
      "4   LightGBM (Tuned)  (see GridSearch log)          0.593513      1553.900028\n",
      "5    Dummy Regressor              0.000662          0.000604      4588.074764\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "\n",
    "# -----------------------\n",
    "# Dummy Regressor (Baseline)\n",
    "# -----------------------\n",
    "dummy_model = DummyRegressor(strategy='mean')\n",
    "\n",
    "start = time.time()\n",
    "dummy_model.fit(X_train, y_train)\n",
    "dummy_train_time = time.time() - start\n",
    "\n",
    "start = time.time()\n",
    "dummy_preds = dummy_model.predict(X_valid)\n",
    "dummy_predict_time = time.time() - start\n",
    "dummy_rmse = mean_squared_error(y_valid, dummy_preds, squared=False)\n",
    "\n",
    "# Add to results DataFrame\n",
    "results.loc[len(results)] = [\n",
    "    'Dummy Regressor',\n",
    "    dummy_train_time,\n",
    "    dummy_predict_time,\n",
    "    dummy_rmse\n",
    "]\n",
    "\n",
    "# Display updated results\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model (Dummy Regressor)\n",
    "\n",
    "To evaluate the effectiveness of our models, we introduced a **Dummy Regressor** that simply predicts the **mean price** from the training data for all cases.\n",
    "\n",
    "| Model              | Validation RMSE |\n",
    "|--------------------|------------------|\n",
    "| Dummy Regressor    | 4588.07          |\n",
    "| Linear Regression  | 2475.58          |\n",
    "| Decision Tree      | 1976.33          |\n",
    "| Random Forest      | 1661.32          |\n",
    "| LightGBM           | 1612.08          |\n",
    "| LightGBM (Tuned)   | **1553.90** ‚úÖ    |\n",
    "\n",
    "### Why It Matters:\n",
    "- The Dummy Regressor sets a **baseline** ‚Äî any real model should do better than this.\n",
    "- All trained models outperform the Dummy model, with **LightGBM (Tuned)** achieving the lowest error.\n",
    "- This validates that our models are **actually learning patterns** from the data instead of guessing blindly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [10, 20],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'num_leaves': [31, 50]\n",
    "}\n",
    "\n",
    "# Prepare training data with categorical dtype\n",
    "X_train_lgbm = X_train.copy()\n",
    "X_valid_lgbm = X_valid.copy()\n",
    "for col in cat_features:\n",
    "    X_train_lgbm[col] = X_train_lgbm[col].astype('category')\n",
    "    X_valid_lgbm[col] = X_valid_lgbm[col].astype('category')\n",
    "\n",
    "# Initialize the base model\n",
    "lgbm_base = LGBMRegressor(random_state=42)\n",
    "\n",
    "# Run GridSearchCV\n",
    "lgbm_grid = GridSearchCV(\n",
    "    lgbm_base,\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the grid search model\n",
    "lgbm_grid.fit(X_train_lgbm, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best estimator from GridSearchCV\n",
    "best_lgbm_model = lgbm_grid.best_estimator_\n",
    "\n",
    "# Prepare test data\n",
    "X_test_lgbm = X_test.copy()\n",
    "for col in cat_features:\n",
    "    X_test_lgbm[col] = X_test_lgbm[col].astype('category')\n",
    "\n",
    "# Predict and evaluate\n",
    "start = time.time()\n",
    "test_preds = best_lgbm_model.predict(X_test_lgbm)\n",
    "test_predict_time = time.time() - start\n",
    "test_rmse = mean_squared_error(y_test, test_preds, squared=False)\n",
    "\n",
    "print(f\"‚úÖ Final Test RMSE (LightGBM Tuned): {test_rmse:.2f}\")\n",
    "print(f\"üïí Test Prediction Time: {test_predict_time:.3f} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison Summary\n",
    "\n",
    "We trained several machine learning models to predict used car prices and compared their performance. Along with the standard models, we added a baseline (Dummy Regressor) and tuned LightGBM for better results.\n",
    "\n",
    "| Model               | Train Time (s)       | Predict Time (s) | Validation RMSE |\n",
    "|--------------------|----------------------|------------------|-----------------|\n",
    "| Linear Regression  | 5.897                | 0.164            | 2475.58         |\n",
    "| Decision Tree      | 0.484                | 0.050            | 1976.33         |\n",
    "| Random Forest      | 20.380               | 0.750            | 1661.32         |\n",
    "| LightGBM           | 1.411                | 0.296            | 1612.08         |\n",
    "| LightGBM (Tuned)   | (see GridSearch log) | 0.529            | **1553.90**     |\n",
    "| Dummy Regressor    | 0.001                | 0.000            | 4588.07         |\n",
    "\n",
    "### Final Test Results\n",
    "- **Best performer**: Tuned LightGBM  \n",
    "- **Test RMSE**: 1605.29  \n",
    "- **Prediction time on test set**: 0.27 seconds\n",
    "\n",
    "### Key Takeaways\n",
    "- The **Dummy Regressor** gives us a baseline to beat‚Äîit just predicts the average.\n",
    "- **Tuned LightGBM** consistently delivered the best RMSE on both validation and test sets.\n",
    "- While **Random Forest** also did well, it took much longer to train.\n",
    "- In real-time systems, **prediction time matters too**, especially if the model needs to be used frequently or at scale.\n",
    "\n",
    "Up next: we'll update the performance plots to include all six models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid gold; padding: 15px; margin: 5px\">\n",
    "<b>   Reviewer's comment </b>\n",
    "    \n",
    "Consider tuning hyperparameters to improve your models.\n",
    "\n",
    "</div>\n",
    "<div style=\"border: 5px solid red; padding: 15px; margin: 5px\">\n",
    "<b>   Reviewer's comment </b>\n",
    "\n",
    "According to the task, we also need to train LightGBM model. Would you try? \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid green; padding: 10px; margin: 5px\">\n",
    "<b>   Reviewer's comment Iter 2</b>\n",
    "    \n",
    "Great job ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure all numeric columns are actually numeric\n",
    "results['Train Time (s)'] = pd.to_numeric(results['Train Time (s)'], errors='coerce')\n",
    "results['Predict Time (s)'] = pd.to_numeric(results['Predict Time (s)'], errors='coerce')\n",
    "results['Validation RMSE'] = pd.to_numeric(results['Validation RMSE'], errors='coerce')\n",
    "\n",
    "# Optionally drop rows with NaNs (from non-numeric values)\n",
    "results_clean = results.dropna(subset=['Train Time (s)', 'Predict Time (s)', 'Validation RMSE'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot RMSE values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(results_clean['Model'], results_clean['Validation RMSE'], color='skyblue')\n",
    "plt.title('Model Comparison by RMSE')\n",
    "plt.ylabel('RMSE (Lower is Better)')\n",
    "plt.xticks(rotation=15)\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Training time\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(results_clean['Model'], results_clean['Train Time (s)'], color='orange')\n",
    "plt.title('Model Comparison by Training Time')\n",
    "plt.ylabel('Time (seconds)')\n",
    "plt.xticks(rotation=15)\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Prediction time\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(results_clean['Model'], results_clean['Predict Time (s)'], color='green')\n",
    "plt.title('Model Comparison by Prediction Time')\n",
    "plt.ylabel('Time (seconds)')\n",
    "plt.xticks(rotation=15)\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid gold; padding: 15px; margin: 5px\">\n",
    "<b>   Reviewer's comment </b>\n",
    "\n",
    "\n",
    "- You can compare the results with a constant baseline. For instance, you can take [DummyRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyRegressor.html). \n",
    "\n",
    "\n",
    "- After we train all models, it is recommended that we choose the best **one** and check its performance on the test subset. Here we only need to make predictions and calculate RMSE. For the final testing, where we use the test subset to check the model's generalization ability, we should use the best model (one model or two models if they have almost the same metric values). We don't use all models here because even just checking their performance influences our choices. This leads to test set leakage when we unconsciously start picking models that perform well on the test set, making it part of the training loop. In real-world scenarios, the test set is meant to reflect how the final model performs in the wild. In practice, you only deploy one model, not several models, so testing just that final one mirrors reality. Moreover, evaluating every tuned model on the test set (especially with big models or datasets) is expensive and time-consuming. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- When choosing the best model, we have to consider prediction time as well. The best model isn't always the one with the lowest error. Sometimes the errors are only slightly different, but the prediction time varies significantly. In such cases, it's worth considering a faster model. Think of a slow search engine that finds 10 useful links versus a fast one that finds 9. This is especially important if the model needs to operate in real time and produce results repeatedly. If a program runs just once, its speed might not even matter. But if it‚Äôs used continuously, optimization becomes crucial. So, in practice, apart from the other requirements, there are also runtime constraints for the model.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison Summary\n",
    "\n",
    "We trained and evaluated several machine learning models to predict used car prices. To get a full picture, we included a simple baseline model (Dummy Regressor) and also tuned hyperparameters for LightGBM to see how far we could push its performance.\n",
    "\n",
    "| Model               | Train Time (s)       | Predict Time (s) | Validation RMSE |\n",
    "|--------------------|----------------------|------------------|-----------------|\n",
    "| Linear Regression  | 5.897                | 0.164            | 2475.58         |\n",
    "| Decision Tree      | 0.484                | 0.050            | 1976.33         |\n",
    "| Random Forest      | 20.380               | 0.750            | 1661.32         |\n",
    "| LightGBM           | 1.411                | 0.296            | 1612.08         |\n",
    "| LightGBM (Tuned)   | (see GridSearch log) | 0.529            | **1553.90**     |\n",
    "| Dummy Regressor    | 0.001                | 0.000            | 4588.07         |\n",
    "\n",
    "### Final Test Results\n",
    "- The best model was the **tuned LightGBM**, which achieved the lowest error.\n",
    "- On the final test set, it produced an RMSE of **1605.29** and made predictions in just 0.27 seconds.\n",
    "\n",
    "### Observations\n",
    "- The **Dummy Regressor** provides a baseline using the mean of the training target values. All real models improved on this, as expected.\n",
    "- **LightGBM** offered a strong balance of speed and accuracy, especially after tuning.\n",
    "- **Random Forest** also performed well, but at a higher training cost.\n",
    "- In practical scenarios, it‚Äôs not just accuracy that matters‚Äî**prediction speed** can be a major factor when deploying models in real-time systems.\n",
    "\n",
    "We‚Äôll now update the performance visualizations to reflect all six models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid green; padding: 10px; margin: 5px\">\n",
    "<b>   Reviewer's comment </b>\n",
    "   \n",
    "Great conclusion! This is a solid final summary with comparison across models.    \n",
    "</div>    \n",
    "<div style=\"border: 5px solid gold; padding: 10px; margin: 5px\">\n",
    "<b>   Reviewer's comment </b>\n",
    "   \n",
    "Try not to make your project (both text and code) look like AI-generated.\n",
    "</div>    \n",
    "<div style=\"border: 5px solid red; padding: 10px; margin: 5px\">\n",
    "<b>   Reviewer's comment </b>\n",
    "    \n",
    "Don't forget to update it if needed. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checklist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type 'x' to check. Then press Shift+Enter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook is open\n",
    "- [x]  Code is error free\n",
    "- [x]  The cells with the code have been arranged in order of execution\n",
    "- [x]  The data has been downloaded and prepared\n",
    "- [x]  The models have been trained\n",
    "- [x]  The analysis of speed and quality of the models has been performed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßæ Project Conclusion\n",
    "\n",
    "We developed a machine learning model to predict the market value of used cars based on features like brand, mileage, fuel type, and engine power. After preparing the data and comparing multiple models, we found that:\n",
    "\n",
    "- **Tuned LightGBM** offered the best overall performance.\n",
    "- It had the lowest validation RMSE (~1553.90) and a strong final test RMSE (~1605.29).\n",
    "- Prediction time was quick (~0.27 seconds), making it practical for real-world use.\n",
    "\n",
    "To ensure fair evaluation, we:\n",
    "- Removed outliers and missing values.\n",
    "- Split the dataset into training, validation, and test sets to prevent data leakage.\n",
    "- Applied different encoding methods:\n",
    "  - `OneHotEncoder` for linear models.\n",
    "  - `OrdinalEncoder` for tree-based models.\n",
    "  - Native category handling for LightGBM.\n",
    "\n",
    "We also included a **Dummy Regressor** as a baseline to confirm that our models actually learned useful patterns.\n",
    "\n",
    "In the end, LightGBM struck the best balance between accuracy and speed, making it well-suited for deployment in pricing systems.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 5px solid green; padding: 10px; margin: 5px\">\n",
    "<b>   Reviewer's comment Iter 2</b>\n",
    "    \n",
    "Congrats on such an excellent project, Taylor!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
